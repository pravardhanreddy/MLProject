{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas is used for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_recall_fscore_support, f1_score, roc_curve, roc_auc_score, RocCurveDisplay, auc\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import svm\n",
    "\n",
    "def convert(data):\n",
    "    number = preprocessing.LabelEncoder()\n",
    "    data['operator'] = number.fit_transform(data.operator)\n",
    "    data['methodReturn'] = number.fit_transform(data.methodReturn)\n",
    "    data['isKilled'] = number.fit_transform(data.isKilled)\n",
    "    return data\n",
    "\n",
    "# Read in data and display first 5 rows\n",
    "features = pd.read_csv('py_files/training_data.csv',encoding= 'unicode_escape')\n",
    "#print(features)\n",
    "#print('The shape of our features is:', features.shape)\n",
    "\n",
    "#Convert string to float\n",
    "features=convert(features)\n",
    "#print(features)\n",
    "#print('The shape of our features is:', features.shape) \n",
    "\n",
    "# Use numpy to convert to arrays\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(features['isKilled'])\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= features.drop('isKilled', axis = 1)\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "# Convert to numpy array\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(414269, 14) (414269,)\n",
      "(177544, 14) (177544,)\n"
     ]
    }
   ],
   "source": [
    "##Validation set create training and testing vars\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3)\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "rbf_0.1 = svm.SVC(kernel='rbf', gamma=0.1, C=1).fit(X_train, y_train)\n",
    "rbf_1 = svm.SVC(kernel='rbf', gamma=1, C=1).fit(X_train, y_train)\n",
    "rbf_5 = svm.SVC(kernel='rbf', gamma=5, C=1).fit(X_train, y_train)\n",
    "rbf_10 = svm.SVC(kernel='rbf', gamma=10, C=1).fit(X_train, y_train)\n",
    "poly_1= svm.SVC(kernel='poly', degree=1, C=1).fit(X_train, y_train)\n",
    "poly_2 = svm.SVC(kernel='poly', degree=2, C=1).fit(X_train, y_train)\n",
    "poly_3 = svm.SVC(kernel='poly', degree=3, C=1).fit(X_train, y_train)\n",
    "poly_4 = svm.SVC(kernel='poly', degree=4, C=1).fit(X_train, y_train)\n",
    "poly_5 = svm.SVC(kernel='poly', degree=5, C=1).fit(X_train, y_train)\n",
    "sig = svm.SVC(kernel='sigmoid', C=1).fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_linear= linear.predict(X_test)\n",
    "y_pred_rbf_0.1= rbf_0.1.predict(X_test)\n",
    "y_pred_rbf_1= rbf_1.predict(X_test)\n",
    "y_pred_rbf_5= rbf_5.predict(X_test)\n",
    "y_pred_rbf_10= rbf_10.predict(X_test)\n",
    "y_pred_poly_1= poly.predict(X_test)\n",
    "y_pred_poly_2= poly.predict(X_test)\n",
    "y_pred_poly_3= poly.predict(X_test)\n",
    "y_pred_poly_4= poly.predict(X_test)\n",
    "y_pred_poly_5= poly.predict(X_test)\n",
    "y_pred_sig= sig.predict(X_test)\n",
    "\n",
    "print(\"SVM Linear kernel Accuracy:\",accuracy_score(y_test, y_pred_linear))\n",
    "print(\"SVM rbf kernel gamma=0.1 Accuracy:\",accuracy_score(y_test, y_pred_rbf_0.1))\n",
    "print(\"SVM rbf kernel gamma=1 Accuracy:\",accuracy_score(y_test, y_pred_rbf_1))\n",
    "print(\"SVM rbf kernel gamma=5 Accuracy:\",accuracy_score(y_test, y_pred_rbf_5))\n",
    "print(\"SVM rbf kernel gamma=10 Accuracy:\",accuracy_score(y_test, y_pred_rbf_10))\n",
    "print(\"SVM polynomial kernel degree=1 Accuracy:\",accuracy_score(y_test, y_pred_poly_1))\n",
    "print(\"SVM polynomial kernel degree=2 Accuracy:\",accuracy_score(y_test, y_pred_poly_2))\n",
    "print(\"SVM polynomial kernel degree=3 Accuracy:\",accuracy_score(y_test, y_pred_poly_3))\n",
    "print(\"SVM polynomial kernel degree=4 Accuracy:\",accuracy_score(y_test, y_pred_poly_4))\n",
    "print(\"SVM polynomial kernel degree=5 Accuracy:\",accuracy_score(y_test, y_pred_poly_5))\n",
    "print(\"SVM sigmoid Accuracy:\",accuracy_score(y_test, y_pred_sig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot feature importance\n",
    "feature_names = [f\"features {i}\" for i in range(features.shape[1])]\n",
    "feature_names = ['DepthTree', 'NumSubclass', 'McCabe', 'LOC','DepthNested','CA','CE','Instability','numCovered','operator','methodReturn','numTestsCover','mutantAssert','classAssert']\n",
    "importances_linear = linear.feature_importances_\n",
    "linear_importances = pd.Series(importances_linear, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "#Feature importance\n",
    "fig, ax = plt.subplots()\n",
    "linear_importances.plot.bar(ax=ax)\n",
    "ax.set_title(\"SVM:Linear Feature importances\")\n",
    "ax.set_ylabel(\"Merit\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot feature importance\n",
    "feature_names = [f\"features {i}\" for i in range(features.shape[1])]\n",
    "feature_names = ['DepthTree', 'NumSubclass', 'McCabe', 'LOC','DepthNested','CA','CE','Instability','numCovered','operator','methodReturn','numTestsCover','mutantAssert','classAssert']\n",
    "importances_rbf_0.1 = rbf_0.1.feature_importances_\n",
    "rbf_0.1_importances = pd.Series(importances_rbf_0.1, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "#Feature importance\n",
    "fig, ax = plt.subplots()\n",
    "rbf_0.1_importances.plot.bar(ax=ax)\n",
    "ax.set_title(\"SVM:rbf:0.1 Feature importances\")\n",
    "ax.set_ylabel(\"Merit\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot feature importance\n",
    "feature_names = [f\"features {i}\" for i in range(features.shape[1])]\n",
    "feature_names = ['DepthTree', 'NumSubclass', 'McCabe', 'LOC','DepthNested','CA','CE','Instability','numCovered','operator','methodReturn','numTestsCover','mutantAssert','classAssert']\n",
    "importances_rbf_1 = rbf_1.feature_importances_\n",
    "rbf_1_importances = pd.Series(importances_rbf_1, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "#Feature importance\n",
    "fig, ax = plt.subplots()\n",
    "rbf_1_importances.plot.bar(ax=ax)\n",
    "ax.set_title(\"SVM:rbf:1 Feature importances\")\n",
    "ax.set_ylabel(\"Merit\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot feature importance\n",
    "feature_names = [f\"features {i}\" for i in range(features.shape[1])]\n",
    "feature_names = ['DepthTree', 'NumSubclass', 'McCabe', 'LOC','DepthNested','CA','CE','Instability','numCovered','operator','methodReturn','numTestsCover','mutantAssert','classAssert']\n",
    "importances_rbf_5 = rbf_5.feature_importances_\n",
    "rbf_5_importances = pd.Series(importances_rbf_5, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "#Feature importance\n",
    "fig, ax = plt.subplots()\n",
    "rbf_5_importances.plot.bar(ax=ax)\n",
    "ax.set_title(\"SVM:rbf:5 Feature importances\")\n",
    "ax.set_ylabel(\"Merit\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot feature importance\n",
    "feature_names = [f\"features {i}\" for i in range(features.shape[1])]\n",
    "feature_names = ['DepthTree', 'NumSubclass', 'McCabe', 'LOC','DepthNested','CA','CE','Instability','numCovered','operator','methodReturn','numTestsCover','mutantAssert','classAssert']\n",
    "importances_rbf_10 = rbf_10.feature_importances_\n",
    "rbf_10_importances = pd.Series(importances_rbf_10, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "#Feature importance\n",
    "fig, ax = plt.subplots()\n",
    "rbf_10_importances.plot.bar(ax=ax)\n",
    "ax.set_title(\"SVM:rbf:10 Feature importances\")\n",
    "ax.set_ylabel(\"Merit\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot feature importance\n",
    "feature_names = [f\"features {i}\" for i in range(features.shape[1])]\n",
    "feature_names = ['DepthTree', 'NumSubclass', 'McCabe', 'LOC','DepthNested','CA','CE','Instability','numCovered','operator','methodReturn','numTestsCover','mutantAssert','classAssert']\n",
    "importances_poly_1 = poly_1.feature_importances_\n",
    "poly_1_importances = pd.Series(importances_poly_1, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "#Feature importance\n",
    "fig, ax = plt.subplots()\n",
    "poly_1_importances.plot.bar(ax=ax)\n",
    "ax.set_title(\"SVM:poly:degree:1 Feature importances\")\n",
    "ax.set_ylabel(\"Merit\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot feature importance\n",
    "feature_names = [f\"features {i}\" for i in range(features.shape[1])]\n",
    "feature_names = ['DepthTree', 'NumSubclass', 'McCabe', 'LOC','DepthNested','CA','CE','Instability','numCovered','operator','methodReturn','numTestsCover','mutantAssert','classAssert']\n",
    "importances_poly_2 = poly_2.feature_importances_\n",
    "poly_2_importances = pd.Series(importances_poly_2, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "#Feature importance\n",
    "fig, ax = plt.subplots()\n",
    "poly_2_importances.plot.bar(ax=ax)\n",
    "ax.set_title(\"SVM:poly:degree:2 Feature importances\")\n",
    "ax.set_ylabel(\"Merit\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot feature importance\n",
    "feature_names = [f\"features {i}\" for i in range(features.shape[1])]\n",
    "feature_names = ['DepthTree', 'NumSubclass', 'McCabe', 'LOC','DepthNested','CA','CE','Instability','numCovered','operator','methodReturn','numTestsCover','mutantAssert','classAssert']\n",
    "importances_poly_3 = poly_3.feature_importances_\n",
    "poly_3_importances = pd.Series(importances_poly_3, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "#Feature importance\n",
    "fig, ax = plt.subplots()\n",
    "poly_3_importances.plot.bar(ax=ax)\n",
    "ax.set_title(\"SVM:poly:degree:3 Feature importances\")\n",
    "ax.set_ylabel(\"Merit\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot feature importance\n",
    "feature_names = [f\"features {i}\" for i in range(features.shape[1])]\n",
    "feature_names = ['DepthTree', 'NumSubclass', 'McCabe', 'LOC','DepthNested','CA','CE','Instability','numCovered','operator','methodReturn','numTestsCover','mutantAssert','classAssert']\n",
    "importances_poly_4 = poly_4.feature_importances_\n",
    "poly_4_importances = pd.Series(importances_poly_4, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "#Feature importance\n",
    "fig, ax = plt.subplots()\n",
    "poly_4_importances.plot.bar(ax=ax)\n",
    "ax.set_title(\"SVM:poly:degree:4 Feature importances\")\n",
    "ax.set_ylabel(\"Merit\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot feature importance\n",
    "feature_names = [f\"features {i}\" for i in range(features.shape[1])]\n",
    "feature_names = ['DepthTree', 'NumSubclass', 'McCabe', 'LOC','DepthNested','CA','CE','Instability','numCovered','operator','methodReturn','numTestsCover','mutantAssert','classAssert']\n",
    "importances_poly_5 = poly_5.feature_importances_\n",
    "poly_5_importances = pd.Series(importances_poly_5, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "#Feature importance\n",
    "fig, ax = plt.subplots()\n",
    "poly_5_importances.plot.bar(ax=ax)\n",
    "ax.set_title(\"SVM:poly:degree:5 Feature importances\")\n",
    "ax.set_ylabel(\"Merit\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot feature importance\n",
    "feature_names = [f\"features {i}\" for i in range(features.shape[1])]\n",
    "feature_names = ['DepthTree', 'NumSubclass', 'McCabe', 'LOC','DepthNested','CA','CE','Instability','numCovered','operator','methodReturn','numTestsCover','mutantAssert','classAssert']\n",
    "importances_sig = sig.feature_importances_\n",
    "sig_importances = pd.Series(importances_sig, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "#Feature importance\n",
    "fig, ax = plt.subplots()\n",
    "sig_importances.plot.bar(ax=ax)\n",
    "ax.set_title(\"SVM:sigmoid Feature importances\")\n",
    "ax.set_ylabel(\"Merit\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Input test data\n",
    "test = pd.read_csv('py_files/testing_data.csv',encoding= 'unicode_escape')\n",
    "\n",
    "#Convert string to float\n",
    "test=convert(test)\n",
    "\n",
    "# ## Labels are the values we want to predict\n",
    "test_labels = np.array(test['isKilled'])\n",
    "\n",
    "# # Remove the labels from the features\n",
    "# # axis 1 refers to the columns\n",
    "test= test.drop('isKilled', axis = 1)\n",
    "# # Saving feature names for later use\n",
    "feature_list = list(test.columns)\n",
    "# # Convert to numpy array\n",
    "test = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict test\n",
    "y_pred_test_linear = linear.predict(test)\n",
    "y_pred_test_rbf_0.1= rbf_0.1.predict(test)\n",
    "y_pred_test_rbf_1= rbf_1.predict(test)\n",
    "y_pred_test_rbf_5= rbf_5.predict(test)\n",
    "y_pred_test_rbf_10= rbf_10.predict(test)\n",
    "y_pred_test_poly_1= poly.predict(test)\n",
    "y_pred_test_poly_2= poly.predict(test)\n",
    "y_pred_test_poly_3= poly.predict(test)\n",
    "y_pred_test_poly_4= poly.predict(test)\n",
    "y_pred_test_poly_5= poly.predict(test)\n",
    "y_pred_test_sig= sig.predict(test)\n",
    "\n",
    "\n",
    "print(\"SVM Linear kernel Accuracy on test:\", accuracy_score(test_labels, y_pred_test_linear))\n",
    "print(\"SVM rbf kernel gamma=0.1 Accuracy on test:\",accuracy_score(test_labels, y_pred_test_rbf_0.1))\n",
    "print(\"SVM rbf kernel gamma=1 Accuracy on test:\",accuracy_score(test_labels, y_pred_test_rbf_1))\n",
    "print(\"SVM rbf kernel gamma=5 Accuracy on test:\",accuracy_score(test_labels, y_pred_test_rbf_5))\n",
    "print(\"SVM rbf kernel gamma=10 Accuracy on test:\",accuracy_score(test_labels, y_pred_test_rbf_10))\n",
    "print(\"SVM polynomial kernel degree=1 Accuracy on test:\",accuracy_score(test_labels, y_pred_test_poly_1))\n",
    "print(\"SVM polynomial kernel degree=2 Accuracy on test:\",accuracy_score(test_labels, y_pred_test_poly_2))\n",
    "print(\"SVM polynomial kernel degree=3 Accuracy on test:\",accuracy_score(test_labels, y_pred_test_poly_3))\n",
    "print(\"SVM polynomial kernel degree=4 Accuracy on test:\",accuracy_score(test_labels, y_pred_test_poly_4))\n",
    "print(\"SVM polynomial kernel degree=5 Accuracy on test:\",accuracy_score(test_labels, y_pred_test_poly_5))\n",
    "print(\"SVM sigmoid Accuracy on test:\",accuracy_score(test_labels, y_pred_test_sig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
